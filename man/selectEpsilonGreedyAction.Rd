% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/actionSelection.R
\name{selectEpsilonGreedyAction}
\alias{selectEpsilonGreedyAction}
\title{Performs \eqn{\varepsilon}-greedy action selection}
\usage{
selectEpsilonGreedyAction(Q, state, epsilon)
}
\arguments{
\item{Q}{State-action table of type \code{hash}.}

\item{state}{The current state.}

\item{epsilon}{Exploration rate between 0 and 1.}
}
\value{
Character value defining the next action.
}
\description{
Implements \eqn{\varepsilon}-greedy action selection. In this strategy, the agent explores the environment
by selecting an action at random with probability \eqn{\varepsilon}. Alternatively, the agent exploits its
current knowledge by choosing the optimal action with probability \eqn{1-\varepsilon}.
}
\references{
Sutton and Barto (1998). "Reinforcement Learning: An Introduction", MIT Press, Cambridge, MA.
}
